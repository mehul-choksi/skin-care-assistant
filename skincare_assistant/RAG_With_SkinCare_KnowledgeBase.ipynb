{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Prerequisites\n",
        "\n",
        "1. Have an OpenAI api key\n",
        "2. Have an Ngrok token\n",
        "3. Ensure that skincare_knowledge_base.zip has been uploaded to the colab environment"
      ],
      "metadata": {
        "id": "n4eItkRS_kER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index langchain openai tqdm typing -q\n",
        "!pip install flask flask-ngrok -q"
      ],
      "metadata": {
        "id": "qSKtl4qNBpKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dccdb5f-28d8-4b57-f8e3-3e21fe61c185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "zPCIc5fFNBEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atPJ2EUFBkPz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "import torch\n",
        "\n",
        "from llama_index.llms.openai.base import OpenAI\n",
        "\n",
        "from llama_index.core import SimpleDirectoryReader, Settings\n",
        "from llama_index.core.indices.vector_store.base import VectorStoreIndex\n",
        "from llama_index.core.vector_stores.simple import SimpleVectorStore\n",
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "from llama_index.core.base.embeddings.base import BaseEmbedding\n",
        "\n",
        "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from typing import List\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project keys and configurations"
      ],
      "metadata": {
        "id": "UnbwOv0oNCZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"your_open_ai_api_key\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your_open_ai_api_key\"\n",
        "Settings.llm = OpenAI(model='gpt-4o')\n"
      ],
      "metadata": {
        "id": "nqOmkGqmHq5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize knowledge base"
      ],
      "metadata": {
        "id": "9q01cIWu3ZII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extract the zip file and get all skin care recommendation data"
      ],
      "metadata": {
        "id": "x5z1FkJc3gCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_zip(zip_file, destination_folder):\n",
        "    if not os.path.exists(zip_file):\n",
        "        print(f\"ZIP file '{zip_file}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "            zip_ref.extractall(destination_folder)\n",
        "        print(f\"Extracted '{zip_file}' to '{destination_folder}'.\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"Error: '{zip_file}' is not a valid ZIP file.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting '{zip_file}': {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    zip_file = \"skincare_knowledge_base.zip\"\n",
        "    destination_folder = \"skincare_knowledge_base\"\n",
        "    extract_zip(zip_file, destination_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHoQbTSE3X2b",
        "outputId": "0d2bc5c7-8d48-4122-bd9b-17f2155ad429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 'skincare_knowledge_base.zip' to 'skincare_knowledge_base'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use GPU, we need to implement a concrete child class of BaseEmbedding in LlamaIndex. This acts as a bridge between AutoModel/Tokenizer and Llama framework"
      ],
      "metadata": {
        "id": "IcQbNmI86fdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "from typing import List\n",
        "import torch\n",
        "\n",
        "class CustomEmbedding(BaseEmbedding):\n",
        "    def __init__(self, model_name: str = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\", **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the CustomEmbedding class with a 1536-dimensional model.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Hugging Face model name that outputs 1536-dimensional embeddings.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self._tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self._model = AutoModel.from_pretrained(model_name).to(\"cuda\")\n",
        "\n",
        "    def _get_query_embedding(self, query: str) -> List[float]:\n",
        "        \"\"\"\n",
        "        Generate embeddings for a single query.\n",
        "\n",
        "        Args:\n",
        "            query (str): Input query string.\n",
        "\n",
        "        Returns:\n",
        "            List[float]: 1536-dimensional embedding for the query.\n",
        "        \"\"\"\n",
        "        return self._get_text_embedding(query)\n",
        "\n",
        "    def _get_text_embedding(self, text: str) -> List[float]:\n",
        "        \"\"\"\n",
        "        Generate embeddings for a single text.\n",
        "\n",
        "        Args:\n",
        "            text (str): Input text string.\n",
        "\n",
        "        Returns:\n",
        "            List[float]: 1536-dimensional embedding for the text.\n",
        "        \"\"\"\n",
        "        inputs = self._tokenizer([text], padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "        with torch.no_grad():\n",
        "            embeddings = self._model(**inputs).last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "        return embeddings[0].tolist()\n",
        "\n",
        "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
        "        \"\"\"\n",
        "        Generate embeddings for a batch of texts.\n",
        "\n",
        "        Args:\n",
        "            texts (List[str]): List of input text strings.\n",
        "\n",
        "        Returns:\n",
        "            List[List[float]]: Batch of 1536-dimensional embeddings.\n",
        "        \"\"\"\n",
        "        inputs = self._tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "        with torch.no_grad():\n",
        "            embeddings = self._model(**inputs).last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "        return embeddings.tolist()\n",
        "\n",
        "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
        "        \"\"\"\n",
        "        Asynchronous implementation of generating embeddings for a single query.\n",
        "\n",
        "        Args:\n",
        "            query (str): Input query string.\n",
        "\n",
        "        Returns:\n",
        "            List[float]: 1536-dimensional embedding for the query.\n",
        "        \"\"\"\n",
        "        return self._get_query_embedding(query)\n",
        "\n",
        "    async def _aget_text_embedding(self, text: str) -> List[float]:\n",
        "        \"\"\"\n",
        "        Asynchronous implementation of generating embeddings for a single text.\n",
        "\n",
        "        Args:\n",
        "            text (str): Input text string.\n",
        "\n",
        "        Returns:\n",
        "            List[float]: 1536-dimensional embedding for the text.\n",
        "        \"\"\"\n",
        "        return self._get_text_embedding(text)\n",
        "\n",
        "    async def _aget_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
        "        \"\"\"\n",
        "        Asynchronous implementation of generating embeddings for a batch of texts.\n",
        "\n",
        "        Args:\n",
        "            texts (List[str]): List of input text strings.\n",
        "\n",
        "        Returns:\n",
        "            List[List[float]]: Batch of 1536-dimensional embeddings.\n",
        "        \"\"\"\n",
        "        return self._get_text_embeddings(texts)\n"
      ],
      "metadata": {
        "id": "ccV02_bo6eim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load the documents, utilize the CustomEmbedding class to vector knowledge store, and save it as an object of VectorStoreIndex.\n",
        "\n",
        "2. This would then be reloaded to provide necessary rag content upon having a user query"
      ],
      "metadata": {
        "id": "WgR_cliA-gWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"./skincare_knowledge_base/\").load_data()"
      ],
      "metadata": {
        "id": "J-TpLQ9d36m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = CustomEmbedding(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
        "index = VectorStoreIndex.from_documents(documents, embed_model=embedding_model)"
      ],
      "metadata": {
        "id": "QG5B-AdaLVeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the name of VectorIndex and save index to disk\n"
      ],
      "metadata": {
        "id": "jlTBuXj83pUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index.set_index_id(\"vector_index\")\n",
        "index.storage_context.persist(persist_dir=\"./storage\")"
      ],
      "metadata": {
        "id": "Tx3c6bmVLbCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load the index to use the skin care knowledge base"
      ],
      "metadata": {
        "id": "_5qxFzzM4LbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "storage_context = StorageContext.from_defaults(persist_dir=\"storage\")\n",
        "index = load_index_from_storage(storage_context, index_id=\"vector_index\")\n"
      ],
      "metadata": {
        "id": "jxHvDSRkLqSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieving top k most relevant documents"
      ],
      "metadata": {
        "id": "KgU0hgue2Vul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(\n",
        "    embed_model=embedding_model,\n",
        "    similarity_top_k=10,\n",
        ")\n"
      ],
      "metadata": {
        "id": "WdvqZcEG2S-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Skincare assistant prompt template"
      ],
      "metadata": {
        "id": "rifCm2X0-S7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "standard_skincare_template = \"\"\"Factor in different types of products used in skincare.\n",
        " We need all products for a dedicated skin routine. Explain what each skin care product does and why do we need it,\n",
        " and generate a skincare routine as well. A skincare routine should consist of 2 phases - a morning skincare routine and a nighttime routine.\n",
        " Analyze what products should be applied when - for eg: retinol is only applied at nighttime, to minimize sun damage whereas vitamin C is applied in the morning.\n",
        " If there's a recommendation that requires prescription, or triggers allergies, alert the user regarding the same.\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "OswsVTvZTnBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sanity testing"
      ],
      "metadata": {
        "id": "RZo5wMsI-WZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_case_1 = \"\"\"Recommend me some skin care prducts for dry, sensitive skin. \"\"\""
      ],
      "metadata": {
        "id": "XzgBzTr3S_yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(standard_skincare_template + test_case_1)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4xKtOyKAd49",
        "outputId": "34ccc7e2-9763-46ba-c7a6-1ffd31cd431c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For a comprehensive skincare routine, various products play essential roles in maintaining healthy skin. Here is a breakdown of different skincare products and their purposes:\n",
            "\n",
            "1. Cleanser: Cleansers remove dirt, oil, and impurities from the skin, preparing it for other products.\n",
            "2. Toner: Toners help balance the skin's pH levels and can provide additional hydration.\n",
            "3. Serum: Serums are concentrated formulas that target specific skin concerns like hydration, brightening, or anti-aging.\n",
            "4. Moisturizer: Moisturizers hydrate the skin, lock in moisture, and create a protective barrier.\n",
            "5. Sunscreen: Sunscreen protects the skin from harmful UV rays, preventing premature aging and skin damage.\n",
            "6. Retinol: Retinol is a powerful ingredient that promotes skin renewal and reduces the appearance of fine lines and wrinkles.\n",
            "7. Vitamin C: Vitamin C brightens the skin, evens out skin tone, and provides antioxidant protection.\n",
            "\n",
            "For a skincare routine tailored to dry, sensitive skin, here is a suggested regimen:\n",
            "\n",
            "Morning Skincare Routine:\n",
            "1. Cleanser: Gentle, non-foaming cleanser\n",
            "2. Vitamin C Serum: Provides antioxidant protection and brightens the skin\n",
            "3. Moisturizer: Hydrating cream with SPF 30 or higher\n",
            "4. Sunscreen: Protects against UV damage\n",
            "\n",
            "Nighttime Skincare Routine:\n",
            "1. Cleansing Balm or Micellar Water: Removes makeup and impurities\n",
            "2. Hydrating Cleanser: Cleanses without stripping the skin\n",
            "3. Hyaluronic Acid Serum: Provides intense hydration\n",
            "4. Moisturizer: Rich cream to nourish and repair the skin\n",
            "5. Retinol: Promotes skin renewal and collagen production\n",
            "6. Optional: Face Oil: Locks in moisture for added hydration\n",
            "\n",
            "It's important to note that retinol should only be applied at night to minimize sun damage. Additionally, some products may require a prescription, such as certain retinoids, so consulting a dermatologist is recommended. For individuals with sensitive skin, it's crucial to patch-test new products and avoid ingredients that may trigger allergies or irritation.\n",
            "\n",
            "Recommended skincare products for dry, sensitive skin:\n",
            "1. Cleanser: Cetaphil Gentle Skin Cleanser\n",
            "2. Serum: La Roche-Posay Hyalu B5 Hyaluronic Acid Serum\n",
            "3. Moisturizer: CeraVe Moisturizing Cream\n",
            "4. Sunscreen: EltaMD UV Clear Broad-Spectrum SPF 46\n",
            "5. Retinol: Paula's Choice Clinical 1% Retinol Treatment\n",
            "6. Vitamin C Serum: Skinceuticals C E Ferulic\n",
            "\n",
            "Always prioritize gentle, hydrating products for dry, sensitive skin and adjust the routine based on individual skin needs and sensitivities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(standard_skincare_template + test_case_1)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFnnjomlMKpK",
        "outputId": "860cfae2-6360-4dca-adf9-582aff44d7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For a comprehensive skincare routine, various products play essential roles in maintaining healthy skin. Here is a breakdown of different skincare products and their purposes:\n",
            "\n",
            "1. Cleanser: Cleansers remove dirt, oil, and impurities from the skin, preparing it for other products.\n",
            "2. Toner: Toners help balance the skin's pH levels and can provide additional hydration.\n",
            "3. Serum: Serums are concentrated formulas that target specific skin concerns like hydration, brightening, or anti-aging.\n",
            "4. Moisturizer: Moisturizers hydrate the skin, lock in moisture, and create a protective barrier.\n",
            "5. Sunscreen: Sunscreen protects the skin from harmful UV rays, preventing premature aging and skin damage.\n",
            "6. Exfoliator: Exfoliators remove dead skin cells, promoting cell turnover and revealing smoother skin.\n",
            "7. Treatment Products: Targeted treatments like retinol or acne spot treatments address specific skin concerns.\n",
            "\n",
            "For a skincare routine tailored to dry, sensitive skin, here is a suggested regimen:\n",
            "\n",
            "Morning Skincare Routine:\n",
            "1. Gentle, non-foaming cleanser\n",
            "2. Hydrating serum with hyaluronic acid\n",
            "3. Moisturizer with SPF 30 or higher\n",
            "4. Sunscreen\n",
            "\n",
            "Nighttime Skincare Routine:\n",
            "1. Cleansing balm or gentle cleanser\n",
            "2. Hydrating serum with soothing ingredients\n",
            "3. Moisturizer, preferably a heavier cream\n",
            "4. Optional: Targeted treatment for specific concerns (if prescribed by a dermatologist)\n",
            "\n",
            "In this routine, products like sunscreen and vitamin C serum are used in the morning to protect the skin from UV damage and provide antioxidant benefits. Retinol or other treatment products are recommended for nighttime use to avoid sun sensitivity. \n",
            "\n",
            "For dry, sensitive skin, it's important to choose products that are gentle and hydrating. Look for ingredients like ceramides, hyaluronic acid, and niacinamide to soothe and moisturize the skin without causing irritation. Avoid products with fragrances, alcohol, or harsh exfoliants that can trigger sensitivity.\n",
            "\n",
            "If any product recommendation requires a prescription or has the potential to trigger allergies, it's advisable to consult a dermatologist before incorporating it into your routine to ensure safety and effectiveness.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Util script to update path\n",
        "\n",
        "Since llamaIndex is a library that changes its file locations frequently, code to do a dfs search over the python module folder"
      ],
      "metadata": {
        "id": "Zld587_mF_zK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import importlib.util\n",
        "\n",
        "def find_class_in_package(package_name, class_name):\n",
        "    try:\n",
        "        spec = importlib.util.find_spec(package_name)\n",
        "        if not spec or not spec.submodule_search_locations:\n",
        "            print(f\"Package '{package_name}' not found.\")\n",
        "            return None\n",
        "\n",
        "        package_path = next(iter(spec.submodule_search_locations))\n",
        "        class_imports = []\n",
        "\n",
        "        for root, _, files in os.walk(package_path):\n",
        "            for file in files:\n",
        "                if file.endswith(\".py\"):\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                        content = f.read()\n",
        "\n",
        "                    if f'class {class_name}' in content:\n",
        "                        module_path = os.path.relpath(file_path, package_path).replace(os.sep, '.').removesuffix('.py')\n",
        "                        import_statement = f\"from {package_name}.{module_path} import {class_name}\"\n",
        "                        class_imports.append(import_statement)\n",
        "\n",
        "        if class_imports:\n",
        "            return class_imports\n",
        "        else:\n",
        "            print(f\"Class '{class_name}' not found in package '{package_name}'.\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    package = \"llama_index\"\n",
        "    class_to_find = \"OpenAI\"\n",
        "\n",
        "    result = find_class_in_package(package, class_to_find)\n",
        "    if result:\n",
        "        print(\"Found import statements:\")\n",
        "        for import_statement in result:\n",
        "            print(import_statement)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqyv7gZKCOvG",
        "outputId": "a004dffc-4912-40f6-a009-6505225f222e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found import statements:\n",
            "from llama_index.legacy.finetuning.openai.base import OpenAI\n",
            "from llama_index.legacy.agent.openai_assistant_agent import OpenAI\n",
            "from llama_index.legacy.agent.legacy.openai_agent import OpenAI\n",
            "from llama_index.legacy.agent.openai.base import OpenAI\n",
            "from llama_index.legacy.agent.openai.step import OpenAI\n",
            "from llama_index.legacy.llms.openai_like import OpenAI\n",
            "from llama_index.legacy.llms.openai import OpenAI\n",
            "from llama_index.legacy.multi_modal_llms.openai import OpenAI\n",
            "from llama_index.legacy.callbacks.finetuning_handler import OpenAI\n",
            "from llama_index.legacy.embeddings.openai import OpenAI\n",
            "from llama_index.legacy.question_gen.openai_generator import OpenAI\n",
            "from llama_index.legacy.program.openai_program import OpenAI\n",
            "from llama_index.agent.openai.openai_assistant_agent import OpenAI\n",
            "from llama_index.agent.openai.base import OpenAI\n",
            "from llama_index.agent.openai.step import OpenAI\n",
            "from llama_index.llms.openai.base import OpenAI\n",
            "from llama_index.multi_modal_llms.openai.base import OpenAI\n",
            "from llama_index.embeddings.openai.base import OpenAI\n",
            "from llama_index.question_gen.openai.base import OpenAI\n",
            "from llama_index.program.openai.base import OpenAI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing ngrok on colab"
      ],
      "metadata": {
        "id": "PieJ9MfQ-Nmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O ngrok.zip https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.zip\n",
        "!unzip -o ngrok.zip\n",
        "!chmod +x ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g83ubDmiddHX",
        "outputId": "602a00c1-c891-4378-86e0-f70aced69221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ngrok.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u6fgbRJbeOAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./ngrok config add-authtoken [your_ngrok_token_here]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnQURtntdmp1",
        "outputId": "6c5624b0-3c0a-43ef-8daa-8d3580754048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flask web app: To expose skincare rag llm as a web application\n",
        "\n",
        "Note: To run the web app correctly, you must:\n",
        "1. Create a templates folder and upload index.html.\n",
        "2. Create a static folder and upload typing_bubble.gif\n",
        "\n",
        "Both of these folders are provided in the github repository.\n"
      ],
      "metadata": {
        "id": "HBQf0RYz757u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "from flask import Flask, render_template, request\n",
        "import os\n",
        "import logging\n",
        "import requests\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "log_file = \"app.log\"\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        "    handlers=[\n",
        "        logging.FileHandler(log_file, mode=\"a\"),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "stop_flag = threading.Event()\n",
        "\n",
        "def get_openai_response(user_input):\n",
        "    try:\n",
        "        logger.info(f\"Received input: {user_input}\")\n",
        "        response = query_engine.query(standard_skincare_template + user_input)\n",
        "        logger.info(f\"Generated response: {response}\")\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error while processing input: {str(e)}\")\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def process_response(response):\n",
        "    general_advice = \"No general advice provided.\"\n",
        "    morning_routine = \"No morning routine provided.\"\n",
        "    night_routine = \"No night routine provided.\"\n",
        "\n",
        "    lower_response = response.lower()\n",
        "    morning_index = lower_response.find(\"morning\")\n",
        "    night_index = lower_response.find(\"night\")\n",
        "\n",
        "    if morning_index != -1:\n",
        "        general_advice = response[:morning_index].strip()\n",
        "        if night_index != -1:\n",
        "            morning_routine = response[morning_index:night_index].strip()\n",
        "            night_routine = response[night_index:].strip()\n",
        "        else:\n",
        "            morning_routine = response[morning_index:].strip()\n",
        "    elif night_index != -1:\n",
        "        general_advice = response[:night_index].strip()\n",
        "        night_routine = response[night_index:].strip()\n",
        "    else:\n",
        "        general_advice = response.strip()\n",
        "\n",
        "    logger.info(\"Response split into sections.\")\n",
        "    logger.info(f\"General Advice: {general_advice}\")\n",
        "    logger.info(f\"Morning Routine: {morning_routine}\")\n",
        "    logger.info(f\"Night Routine: {night_routine}\")\n",
        "\n",
        "    return general_advice, morning_routine, night_routine\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def index():\n",
        "    if request.method == \"POST\":\n",
        "        user_prompt = request.form[\"prompt\"]\n",
        "        logger.info(\"Handling POST request.\")\n",
        "        response = get_openai_response(user_prompt)\n",
        "        general_advice, morning_routine, night_routine = process_response(response)\n",
        "        return render_template(\n",
        "            \"index.html\",\n",
        "            prompt=user_prompt,\n",
        "            general_advice=general_advice,\n",
        "            morning_routine=morning_routine,\n",
        "            night_routine=night_routine,\n",
        "        )\n",
        "    logger.info(\"Serving GET request.\")\n",
        "    return render_template(\"index.html\", prompt=\"\", general_advice=\"\", morning_routine=\"\", night_routine=\"\")\n",
        "\n",
        "@app.route('/hello')\n",
        "def hello():\n",
        "    logger.info(\"Accessed '/hello' route.\")\n",
        "    return \"Hello, Flask is running in the background with ngrok!\"\n",
        "\n",
        "@app.route(\"/shutdown\", methods=[\"POST\"])\n",
        "def shutdown():\n",
        "    func = request.environ.get('werkzeug.server.shutdown')\n",
        "    if func is None:\n",
        "        raise RuntimeError(\"Not running the Werkzeug Server\")\n",
        "    logger.info(\"Shutting down Flask server.\")\n",
        "    stop_flag.set()\n",
        "    func()\n",
        "    return \"Server shutting down...\"\n",
        "\n",
        "def run_app():\n",
        "    logger.info(\"Starting ngrok.\")\n",
        "    os.system(\"./ngrok http 5000 &\")\n",
        "    logger.info(\"Starting Flask app.\")\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n",
        "\n",
        "flask_thread = threading.Thread(target=run_app, name=\"FlaskThread\")\n",
        "flask_thread.setDaemon(True)\n",
        "flask_thread.start()\n",
        "\n",
        "logger.info(\"Flask app is running in the background. Continue with other notebook cells.\")\n",
        "\n",
        "def stop_flask_thread():\n",
        "    try:\n",
        "        logger.info(\"Attempting to shut down Flask thread.\")\n",
        "        response = requests.post(\"http://127.0.0.1:5000/shutdown\")\n",
        "        logger.info(response.text)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error shutting down Flask thread: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1wQaAKBqHpl",
        "outputId": "739e1c3b-4e98-4dee-8774-999c85fd3d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flask app is running in the background. Continue with other notebook cells.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-159-abe1920aaa70>:49: DeprecationWarning: setDaemon() is deprecated, set the daemon attribute instead\n",
            "  flask_thread.setDaemon(True)  # Set as a daemon thread\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dev testing only: Utils related to terminating flask web app sitting behind ngrok endpoint"
      ],
      "metadata": {
        "id": "wGb5jtDQ7eyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import signal\n",
        "\n",
        "# Get the current process's PID\n",
        "current_pid = os.getpid()\n",
        "current_pid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA-sVPoPuR1Z",
        "outputId": "c5c402ad-2954-4c29-e086-20e0d0fac067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "895"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import os\n",
        "\n",
        "def list_child_processes():\n",
        "    current_process = psutil.Process(os.getpid())\n",
        "    children = current_process.children(recursive=True)\n",
        "    for child in children:\n",
        "        print(f\"PID: {child.pid}, Name: {child.name()}, CMDLINE: {child.cmdline()}\")\n",
        "\n",
        "list_child_processes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWDBNuTmtZd3",
        "outputId": "60f38f40-8042-4b87-8470-b765c4ec9697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PID: 58375, Name: ngrok, CMDLINE: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def terminate_child_process(pid):\n",
        "    try:\n",
        "        child = psutil.Process(pid)\n",
        "        child.terminate()\n",
        "        print(f\"Terminated process with PID: {pid}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "terminate_child_process(<PID>)  # Replace <PID> with the correct PID\n"
      ],
      "metadata": {
        "id": "RRUzSdlftd7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ps -ax | grep 'python3'\n",
        "# !kill -9 58375"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibhpXdzpcrlv",
        "outputId": "d612962d-6613-41b8-ad33-6d16b0b20f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     64 ?        Z      0:12 [python3] <defunct>\n",
            "     65 ?        S      0:05 python3 /usr/local/bin/colab-fileshim.py\n",
            "    114 ?        Sl     0:12 /usr/bin/python3 /usr/local/bin/jupyter-notebook --debug --transport=\"i\n",
            "    895 ?        Ssl    2:15 /usr/bin/python3 -m colab_kernel_launcher -f /root/.local/share/jupyter\n",
            "    926 ?        Sl     0:30 /usr/bin/python3 /usr/local/lib/python3.10/dist-packages/debugpy/adapte\n",
            "  59805 ?        S      0:00 /bin/bash -c ps -ax | grep 'python3'\n",
            "  59807 ?        S      0:00 grep python3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "for thread in threading.enumerate():\n",
        "    print(f\"Thread: {thread.name}, Alive: {thread.is_alive()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B-KMG_YukhD",
        "outputId": "691921a4-eca1-47c4-b641-5fcce2f69b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread: MainThread, Alive: True\n",
            "Thread: Thread-2 (_thread_main), Alive: True\n",
            "Thread: Thread-3, Alive: True\n",
            "Thread: Thread-1, Alive: True\n",
            "Thread: _colab_inspector_thread, Alive: True\n",
            "Thread: Thread-10, Alive: True\n",
            "Thread: Thread-11 (run_app), Alive: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ps aux | grep ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-CteW0yrQbF",
        "outputId": "1af2db19-ac59-419d-aab5-381f3696672d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root       57779  0.0  0.0   7376  3512 ?        S    07:16   0:00 /bin/bash -c ps aux | grep ngrok\n",
            "root       57783  0.0  0.0   6484  2316 ?        S    07:16   0:00 grep ngrok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "def start_ngrok():\n",
        "    process = subprocess.Popen([\"./ngrok\", \"http\", \"5000\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    print(f\"ngrok started with PID: {process.pid}\")\n",
        "    return process\n",
        "\n",
        "ngrok_process = start_ngrok()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOGsA-thrlCX",
        "outputId": "c08432a0-c04e-4326-fe6f-485da85c1cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok started with PID: 58375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl localhost:4040/api/tunnels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxyXlJczrYOi",
        "outputId": "795d979f-fe87-4258-ea89-b4a53e3c91ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"tunnels\":[{\"name\":\"command_line\",\"ID\":\"e139350b06e1dba52395203939e9f4fd\",\"uri\":\"/api/tunnels/command_line\",\"public_url\":\"https://f35a-34-87-41-212.ngrok-free.app\",\"proto\":\"https\",\"config\":{\"addr\":\"http://localhost:5000\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":0,\"gauge\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0},\"http\":{\"count\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0}}}],\"uri\":\"/api/tunnels\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get(\"http://localhost:4040/api/tunnels\")\n",
        "data = response.json()\n",
        "public_url = data['tunnels'][0]['public_url']\n",
        "print(f\"Public URL: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECyCb7h-dDSw",
        "outputId": "a07256c3-f5f7-4ae7-b4d9-0d3087310f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://f35a-34-87-41-212.ngrok-free.app\n"
          ]
        }
      ]
    }
  ]
}